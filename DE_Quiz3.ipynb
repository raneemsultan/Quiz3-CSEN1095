{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DE-Quiz3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wYTAA4MKqPKr",
        "B8U1LRF1qZwz"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhQXB6WLp6H3"
      },
      "source": [
        "# **Duration: 30 minutes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tV0g6krwXMy"
      },
      "source": [
        "# **NOTE**: Make sure you create your own copy of the notebook for Spark to work without problems. Don't use GitHub's Colab extension. (Download the notebook -> upload in Colab and solve the quiz -> upload the finished notebook to GitHub)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYTAA4MKqPKr"
      },
      "source": [
        "# Run the cells below to insantiate a Spark session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGVaTOzLnlO1"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\r\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.1/spark-3.0.1-bin-hadoop2.7.tgz  #install Apache Spark\r\n",
        "!tar xf spark-3.0.1-bin-hadoop2.7.tgz  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-_OuoDAnlIr"
      },
      "source": [
        "!pip install pyspark==3.0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AylgXuUnlAk"
      },
      "source": [
        "import os \r\n",
        "os.environ['JAVA_HOME']='/usr/lib/jvm/java-8-openjdk-amd64'\r\n",
        "os.environ['SPARK_HOME']='/content/spark-3.0.1-bin-hadoop2.7'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p-Qx2JEnrbr"
      },
      "source": [
        "import pyspark\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "from pyspark import SparkContext\r\n",
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"quiz\").getOrCreate()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8U1LRF1qZwz"
      },
      "source": [
        "# Reading The Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcBS2DA4yXE0"
      },
      "source": [
        "You will be working with the adult dataset found here: https://raw.githubusercontent.com/raneemsultan/DataEngineering-CSEN1095/main/Lab6/CSVs/adult.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIaAaw3mpprI"
      },
      "source": [
        "## The following cell will read the csv file from the url into \"adult\" variable so you can use it to solve the questions below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpePNL7Uw6TG"
      },
      "source": [
        "from pyspark import SparkFiles\r\n",
        "\r\n",
        "spark.sparkContext.addFile(\"https://raw.githubusercontent.com/raneemsultan/DataEngineering-CSEN1095/main/Lab6/CSVs/adult.csv\")\r\n",
        "\r\n",
        "adult = spark.read.csv(SparkFiles.get(\"adult.csv\"), header=True, inferSchema=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_oVFekCw45K"
      },
      "source": [
        "# Question 1 - 4 Marks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBTKm9Ixw_GZ"
      },
      "source": [
        "Using PySpark Querying or Spark SQL, **display** the average **age** according to the **workclass**. Sort the age averages **ascendingly**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDn1fSgaLkgL"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSIfEJ31w8-W"
      },
      "source": [
        "# Question 2 - 6 Marks Total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSDozMdTQ5jl"
      },
      "source": [
        "## Part a - 3 Marks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deu6ZEw3xLjH"
      },
      "source": [
        "Using Spark Mlib, perform label encoding on the **workclass** column.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLFjA98CvXeG"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKy89iSWQ9d0"
      },
      "source": [
        "## Part b - 3 Marks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_o1pKRV7xeQi"
      },
      "source": [
        "Using Spark Mlib, perform one hot-encoding on the **educational-num** column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbyMvknTtFK7"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}